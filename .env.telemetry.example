# OpenTelemetry Configuration for AI Chatbot
# Copy this file to .env.local and configure the values for your environment

# =============================================================================
# OPENTELEMETRY CONFIGURATION
# =============================================================================

# Enable/disable telemetry components
OTEL_TRACES_ENABLED=true
OTEL_METRICS_ENABLED=true
OTEL_LOGS_ENABLED=true

# OpenTelemetry Collector endpoints
# For local development with Docker Compose:
OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://localhost:4318/v1/traces
OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=http://localhost:4318/v1/metrics
OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=http://localhost:4318/v1/logs

# For production with external OTLP endpoint:
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://your-otlp-endpoint.com/v1/traces
# OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=https://your-otlp-endpoint.com/v1/metrics
# OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=https://your-otlp-endpoint.com/v1/logs

# Authentication headers for OTLP endpoints (JSON format)
# OTEL_EXPORTER_OTLP_HEADERS={"Authorization":"Bearer your-token","X-API-Key":"your-api-key"}

# Sampling configuration
OTEL_TRACES_SAMPLE_RATE=1.0

# Metrics export interval (milliseconds)
OTEL_METRICS_EXPORT_INTERVAL_MS=30000

# Log level for OpenTelemetry
OTEL_LOG_LEVEL=info

# =============================================================================
# CLIENT-SIDE TELEMETRY CONFIGURATION
# =============================================================================

# Enable/disable client-side telemetry
NEXT_PUBLIC_OTEL_TRACES_ENABLED=true
NEXT_PUBLIC_OTEL_LOGS_ENABLED=true

# Client-side telemetry endpoints (relative to your app)
NEXT_PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=/api/telemetry/traces
NEXT_PUBLIC_OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=/api/telemetry/logs

# =============================================================================
# POPULAR OBSERVABILITY PLATFORMS
# =============================================================================

# Jaeger (for tracing)
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://localhost:14268/api/traces
# OTEL_EXPORTER_OTLP_HEADERS={}

# Zipkin (for tracing)
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://localhost:9411/api/v2/spans
# OTEL_EXPORTER_OTLP_HEADERS={}

# Prometheus (for metrics) - typically uses pull model, not push
# Configure Prometheus to scrape metrics from your app

# Grafana Cloud
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://tempo-prod-04-prod-us-central-0.grafana.net:443/tempo/api/traces
# OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=https://prometheus-prod-01-prod-us-central-0.grafana.net/api/prom/push
# OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=https://logs-prod-006.grafana.net/loki/api/v1/push
# OTEL_EXPORTER_OTLP_HEADERS={"Authorization":"Basic base64(username:password)"}

# Honeycomb
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://api.honeycomb.io/v1/traces
# OTEL_EXPORTER_OTLP_HEADERS={"x-honeycomb-team":"your-api-key","x-honeycomb-dataset":"your-dataset"}

# New Relic
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://otlp.nr-data.net:4318/v1/traces
# OTEL_EXPORTER_OTLP_HEADERS={"api-key":"your-license-key"}

# Datadog
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=https://trace.agent.datadoghq.com/v0.4/traces
# OTEL_EXPORTER_OTLP_HEADERS={"DD-API-KEY":"your-api-key"}

# =============================================================================
# DOCKER COMPOSE SETUP FOR LOCAL DEVELOPMENT
# =============================================================================

# To run a local observability stack with Docker Compose, create a docker-compose.yml:
#
# version: '3.8'
# services:
#   # OpenTelemetry Collector
#   otel-collector:
#     image: otel/opentelemetry-collector-contrib:latest
#     command: ["--config=/etc/otel-collector-config.yaml"]
#     volumes:
#       - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
#     ports:
#       - "4317:4317"   # OTLP gRPC receiver
#       - "4318:4318"   # OTLP HTTP receiver
#       - "8889:8889"   # Prometheus metrics
#     depends_on:
#       - jaeger
#       - prometheus
#
#   # Jaeger for tracing
#   jaeger:
#     image: jaegertracing/all-in-one:latest
#     ports:
#       - "16686:16686"
#       - "14250:14250"
#     environment:
#       - COLLECTOR_OTLP_ENABLED=true
#
#   # Prometheus for metrics
#   prometheus:
#     image: prom/prometheus:latest
#     ports:
#       - "9090:9090"
#     volumes:
#       - ./prometheus.yml:/etc/prometheus/prometheus.yml
#
#   # Grafana for visualization
#   grafana:
#     image: grafana/grafana:latest
#     ports:
#       - "3001:3000"
#     environment:
#       - GF_SECURITY_ADMIN_PASSWORD=admin

# =============================================================================
# VERCEL DEPLOYMENT
# =============================================================================

# When deploying to Vercel, the built-in @vercel/otel package will be used automatically
# You can still configure external endpoints for additional observability platforms
# Set these as environment variables in your Vercel project settings

# =============================================================================
# TROUBLESHOOTING
# =============================================================================

# To debug telemetry issues, enable debug logging:
# OTEL_LOG_LEVEL=debug

# To disable specific instrumentations:
# OTEL_TRACES_ENABLED=false
# OTEL_METRICS_ENABLED=false
# OTEL_LOGS_ENABLED=false

# To test telemetry locally without external services:
# OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://localhost:4318/v1/traces
# OTEL_EXPORTER_OTLP_METRICS_ENDPOINT=http://localhost:4318/v1/metrics
# OTEL_EXPORTER_OTLP_LOGS_ENDPOINT=http://localhost:4318/v1/logs
